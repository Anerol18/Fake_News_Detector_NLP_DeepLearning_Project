{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "view-in-github",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anerol18/Fake_News_Detector_NLP_DeepLearning_Project/blob/main/fakenews_project_october_version_stella_nl_V5__from_lorena_with_cv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b78069c6-04c0-470a-b491-4f3948c21114",
      "metadata": {
        "id": "b78069c6-04c0-470a-b491-4f3948c21114"
      },
      "source": [
        "# Environment setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "euiMurqEFA7l",
      "metadata": {
        "id": "euiMurqEFA7l"
      },
      "outputs": [],
      "source": [
        "# Environment setting for Google Colab\n",
        "#!pip install transformers sentence-transformers tqdm\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import normalize\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfONY_eY6GAA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfONY_eY6GAA",
        "outputId": "f22b0ac3-d3f0-49e1-b307-1ec3cbc1d157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flash_attn\n",
            "  Downloading flash_attn-2.6.3.tar.gz (2.6 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/2.6 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m2.4/2.6 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash_attn) (2.5.0+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash_attn) (0.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->flash_attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash_attn) (3.0.2)\n",
            "Building wheels for collected packages: flash_attn\n"
          ]
        }
      ],
      "source": [
        "!pip install flash_attn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U4osI_YG3vUq",
      "metadata": {
        "id": "U4osI_YG3vUq"
      },
      "outputs": [],
      "source": [
        "# If Metal Performance Shader (mps) is not available tell me:\n",
        "if not torch.backends.mps.is_available():\n",
        "    if not torch.backends.mps.is_built():\n",
        "        print(\"MPS not available because the current PyTorch install was not \"\n",
        "              \"built with MPS enabled.\")\n",
        "    else:\n",
        "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
        "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
        "\n",
        "# If mps is available directly put it on the device.\n",
        "else:\n",
        "    device = torch.device(\"mps\")\n",
        ",\n",
        "# If cuda (nvidia gpu) is not available tell me:\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"Cuda not available because the current PyTorch install was not \"\n",
        "              \"built with Cuda enabled.\")\n",
        "\n",
        "\n",
        "# If cuda is available directly put it on the device.\n",
        "else:\n",
        "    device = torch.device(\"cuda\")\n",
        ",\n",
        "\n",
        "# If neither cuda and mps are available, set device to \"cpu\"\n",
        "if not torch.backends.mps.is_available():\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"Neither Cuda nor MPS are available\")\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        ",\n",
        "# Is mps available?\n",
        "\n",
        "mps_avail = torch.backends.mps.is_available()\n",
        "print(f\"Is Metal Performance Shader (mps) available? {mps_avail}\")\n",
        "\n",
        ",\n",
        "\n",
        "# Is mps available?\n",
        "\n",
        "cuda_avail = torch.cuda.is_available()\n",
        "print(f\"Is Cuda available? {cuda_avail}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available and active.\")\n",
        "    print(f\"GPU type: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"GPU is not available.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7f07b50-8f29-4475-8376-728ca909daf6",
      "metadata": {
        "id": "c7f07b50-8f29-4475-8376-728ca909daf6"
      },
      "outputs": [],
      "source": [
        "# Setting seed:\n",
        "\n",
        "def set_seed_fun(seed_number: int):\n",
        "    \"\"\"\n",
        "    We could also use pytorch_lightning package\n",
        "    try:\n",
        "        import pytorch_lightning as pl\n",
        "    except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
        "        !pip install --quiet pytorch-lightning>=1.5\n",
        "        import pytorch_lightning as pl\n",
        "\n",
        "    pl.seed_everything(42)\n",
        "    \"\"\"\n",
        "    np.random.seed(seed_number)\n",
        "    if torch.backends.mps.is_available():\n",
        "        torch.mps.manual_seed(seed_number)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.manual_seed(seed_number)\n",
        "        torch.cuda.manual_seed(seed_number)\n",
        "        torch.cuda.manual_seed_all(seed_number)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchark = False\n",
        "\n",
        "set_seed_fun(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tUaf6SRS53AH",
      "metadata": {
        "id": "tUaf6SRS53AH"
      },
      "outputs": [],
      "source": [
        "# Load the embedding model (dunzhang/stella_en_1.5B_v5)\n",
        "model_name = \"dunzhang/stella_en_1.5B_v5\"\n",
        "model = AutoModel.from_pretrained(model_name, trust_remote_code=True).to(device).eval()\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99e07a94-fbf3-4d20-84bc-822e61682eac",
      "metadata": {
        "id": "99e07a94-fbf3-4d20-84bc-822e61682eac"
      },
      "outputs": [],
      "source": [
        "# Import dataset from github\n",
        "# Raw URL of the CSV file\n",
        "url = 'https://raw.githubusercontent.com/Anerol18/Fake_News_Detector_NLP_DeepLearning_Project/main/final_combined_dataset.csv'\n",
        "df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46d4ab2b-ee2a-4ce9-9b20-c457b0b0ac2c",
      "metadata": {
        "id": "46d4ab2b-ee2a-4ce9-9b20-c457b0b0ac2c"
      },
      "outputs": [],
      "source": [
        "# Prepare data\n",
        "X = df['Text'].values.astype(str)\n",
        "y = (df['Label'] == 'fake').astype(int).values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81a7d200-6a4e-4bb1-a166-05da53b3ab10",
      "metadata": {
        "id": "81a7d200-6a4e-4bb1-a166-05da53b3ab10"
      },
      "outputs": [],
      "source": [
        "# Split the data into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dc6ae47-93f1-40a0-9295-3c75928120c7",
      "metadata": {
        "id": "6dc6ae47-93f1-40a0-9295-3c75928120c7"
      },
      "source": [
        "# Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7Nubkly8ocs",
      "metadata": {
        "id": "b7Nubkly8ocs"
      },
      "outputs": [],
      "source": [
        "# Modified function without dimension reduction\n",
        "def generate_stella_embeddings(texts, tokenizer, model, batch_size=32):\n",
        "    embeddings = []\n",
        "\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Generating Embeddings\"):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = tokenizer(batch_texts, padding=\"longest\", truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n",
        "            attention_mask = inputs[\"attention_mask\"]\n",
        "            outputs = model(**inputs)[0]\n",
        "            last_hidden = outputs.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "            embeddings_batch = last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "            embeddings_batch = normalize(embeddings_batch.cpu().numpy())\n",
        "\n",
        "            embeddings.append(embeddings_batch)\n",
        "\n",
        "    return np.vstack(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "befa178b-cbc7-4d7f-9c96-5cbb828470ee",
      "metadata": {
        "id": "befa178b-cbc7-4d7f-9c96-5cbb828470ee"
      },
      "outputs": [],
      "source": [
        "#####################################\n",
        "# benchmark beginning for embedding #\n",
        "#####################################\n",
        "time_start_embed = time.perf_counter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1Z8m1kVFnTQ",
      "metadata": {
        "id": "a1Z8m1kVFnTQ"
      },
      "outputs": [],
      "source": [
        "# Initialize the Vertex AI TextEmbeddingModel\n",
        "# embedding_model = TextEmbeddingModel.from_pretrained(\"text-embedding-004\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UF22BrrY79RS",
      "metadata": {
        "id": "UF22BrrY79RS"
      },
      "outputs": [],
      "source": [
        "# Ensure data is in the correct format\n",
        "X_train = X_train.tolist() if isinstance(X_train, np.ndarray) else X_train\n",
        "X_val = X_val.tolist() if isinstance(X_val, np.ndarray) else X_val\n",
        "X_test = X_test.tolist() if isinstance(X_test, np.ndarray) else X_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kUiUJO8c9Udz",
      "metadata": {
        "id": "kUiUJO8c9Udz"
      },
      "outputs": [],
      "source": [
        "# Generate embeddings for the train, validation, and test sets\n",
        "X_train_embeddings = generate_stella_embeddings(X_train, tokenizer, model)\n",
        "X_val_embeddings = generate_stella_embeddings(X_val, tokenizer, model)\n",
        "X_test_embeddings = generate_stella_embeddings(X_test, tokenizer, model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb68c53d-0a6c-4f2e-99f6-1c85d0d26ef1",
      "metadata": {
        "id": "eb68c53d-0a6c-4f2e-99f6-1c85d0d26ef1"
      },
      "outputs": [],
      "source": [
        "#####################################\n",
        "# benchmark ending for embedding    #\n",
        "#####################################\n",
        "time_end_embed = time.perf_counter()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc999217-4072-46d1-8e44-b05cd901fa66",
      "metadata": {
        "id": "fc999217-4072-46d1-8e44-b05cd901fa66"
      },
      "source": [
        "# Training part"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7acb5108-17ca-499e-8ecd-b4933f1b2b18",
      "metadata": {
        "id": "7acb5108-17ca-499e-8ecd-b4933f1b2b18"
      },
      "source": [
        "## Class functions\n",
        "\n",
        "Definition of functions to:\n",
        "- Transform a data set into the good format\n",
        "- create a simple neural network architecture\n",
        "- create a funtion to transform seconds into a list of (hours, minutes, seconds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "423bc231-7992-40a8-aaaa-cc7920a72ceb",
      "metadata": {
        "id": "423bc231-7992-40a8-aaaa-cc7920a72ceb"
      },
      "outputs": [],
      "source": [
        "# Define a Dataset class for PyTorch\n",
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "         # Ensure X is a numeric tensor\n",
        "        text_tensor = torch.tensor(self.X[idx], dtype=torch.float32)  # Make sure this is float\n",
        "        label_tensor = torch.tensor(self.y[idx], dtype=torch.long)  # Labels should be long for classification\n",
        "        return text_tensor, label_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bpqcOYYqZ1fv",
      "metadata": {
        "id": "bpqcOYYqZ1fv"
      },
      "outputs": [],
      "source": [
        "# input_size = 1536 / 768 / 384 / 192"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c2b1910-63be-4ca7-ab7d-f441ad81c576",
      "metadata": {
        "id": "8c2b1910-63be-4ca7-ab7d-f441ad81c576"
      },
      "outputs": [],
      "source": [
        "# Define a simple neural network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc0 = nn.Linear(input_size, 3072)\n",
        "        self.dropout0 = nn.Dropout(p=0.6)\n",
        "        self.relu0 = nn.ReLU()\n",
        "        self.fc01 = nn.Linear(3072, 3072)\n",
        "        self.dropout01 = nn.Dropout(p=0.6)\n",
        "        self.relu01 = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(3072, 768)\n",
        "        self.dropout1 = nn.Dropout(p=0.6)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        #self.fc11 = nn.Linear(768, 768)\n",
        "        #self.dropout11 = nn.Dropout(p=0.6)\n",
        "        #self.relu11 = nn.ReLU()\n",
        "        #self.fc2 = nn.Linear(768, 384)\n",
        "        #self.dropout2 = nn.Dropout(p=0.6)\n",
        "        #self.relu2 = nn.ReLU()\n",
        "        #self.fc21 = nn.Linear(384, 384)\n",
        "        #self.dropout21 = nn.Dropout(p=0.6)\n",
        "        #self.relu21 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(768, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc0(x)\n",
        "        x = self.dropout0(x)\n",
        "        x = self.relu0(x)\n",
        "        x = self.fc01(x)\n",
        "        x = self.dropout01(x)\n",
        "        x = self.relu01(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.relu1(x)\n",
        "        #x = self.fc11(x)\n",
        "        #x = self.dropout1(x)\n",
        "        #x = self.relu1(x)\n",
        "        #x = self.fc2(x)\n",
        "        #x = self.dropout2(x)\n",
        "        #x = self.relu2(x)\n",
        "        #x = self.fc21(x)\n",
        "        #x = self.dropout21(x)\n",
        "        #x = self.relu21(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff2fedd9-c85c-4144-8dd5-139af39d891d",
      "metadata": {
        "id": "ff2fedd9-c85c-4144-8dd5-139af39d891d"
      },
      "outputs": [],
      "source": [
        "def sec2hms(ss):\n",
        "\t(hh, ss)=divmod(ss, 3600)\n",
        "\t(mm, ss)=divmod(ss, 60)\n",
        "\treturn (hh, mm, ss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5a1eed2-7a53-4921-9d9f-cb35848dedbf",
      "metadata": {
        "id": "f5a1eed2-7a53-4921-9d9f-cb35848dedbf"
      },
      "source": [
        "## Training function\n",
        "\n",
        "Definition of the training function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c424347-5b2d-42cd-829a-1a36e6dcf742",
      "metadata": {
        "id": "3c424347-5b2d-42cd-829a-1a36e6dcf742"
      },
      "outputs": [],
      "source": [
        "# Function to train the model\n",
        "def train_model(X_train, y_train, X_val, y_val, input_size, n_splits=5):\n",
        "    train_dataset = NewsDataset(X_train, y_train)\n",
        "    val_dataset = NewsDataset(X_val, y_val)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    weight_decay_values = [0, 0.0001 0.001, 0.01, 0.1]  # Added: Range of weight decay values to experiment with\n",
        "    results = {}  # Added: Store results for each weight decay value\n",
        "\n",
        "    for weight_decay in weight_decay_values:  # Added: Loop through each weight decay value\n",
        "        fold_results = []\n",
        "        for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "            print(f\"Training on fold {fold + 1}/{n_splits} with weight decay {weight_decay}\")\n",
        "            model = SimpleNN(input_size).to(device)\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            optimizer = optim.AdamW(model.parameters(), lr=2e-5, weight_decay=weight_decay)\n",
        "\n",
        "            num_epochs = 40\n",
        "            best_val_loss = float('inf')\n",
        "            patience = 2\n",
        "            patience_counter = 0\n",
        "\n",
        "            # Initialize lists to store losses and accuracies\n",
        "            train_losses = []\n",
        "            val_losses = []\n",
        "            train_accuracies = []\n",
        "            val_accuracies = []\n",
        "\n",
        "            for epoch in range(num_epochs):\n",
        "                model.train()\n",
        "                running_loss = 0.0\n",
        "                correct = 0\n",
        "                total = 0\n",
        "\n",
        "                for X_batch, y_batch in train_loader:\n",
        "                    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(X_batch)\n",
        "                    loss = criterion(outputs, y_batch)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    running_loss += loss.item()  # Accumulate training loss\n",
        "\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    total += y_batch.size(0)\n",
        "                    correct += (predicted == y_batch).sum().item()  # Track correct predictions\n",
        "\n",
        "\n",
        "                avg_train_loss = running_loss / len(train_loader)  # Calculate average training loss\n",
        "                train_accuracy = correct / total  # Calculate training accuracy\n",
        "\n",
        "                train_losses.append(avg_train_loss)\n",
        "                train_accuracies.append(train_accuracy)\n",
        "\n",
        "\n",
        "                model.eval()\n",
        "                val_loss = 0\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                with torch.no_grad():\n",
        "                    for X_batch, y_batch in val_loader:\n",
        "                        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                        outputs = model(X_batch)\n",
        "                        loss = criterion(outputs, y_batch)\n",
        "                        val_loss += loss.item()\n",
        "\n",
        "                        _, predicted = torch.max(outputs, 1)\n",
        "                        total += y_batch.size(0)\n",
        "                        correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "                avg_val_loss = val_loss / len(val_loader)\n",
        "                val_accuracy = correct / total\n",
        "\n",
        "                val_losses.append(avg_val_loss)\n",
        "                val_accuracies.append(val_accuracy)\n",
        "                print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss:.6f}, Training Accuracy: {train_accuracy:.6f},\\n Validation Loss: {avg_val_loss:.6f}, Validation Accuracy: {val_accuracy:.6f}')\n",
        "                #print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {avg_val_loss}\n",
        "\n",
        "                if val_loss < best_val_loss:\n",
        "                    best_val_loss = val_loss\n",
        "                    patience_counter = 0\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "\n",
        "                if patience_counter >= patience:\n",
        "                    print(\"Early stopping\")\n",
        "                    break\n",
        "\n",
        "            fold_results.append({\n",
        "                'train_losses': train_losses,\n",
        "                'val_losses': val_losses,\n",
        "                'train_accuracies': train_accuracies,\n",
        "                'val_accuracies': val_accuracies\n",
        "            })\n",
        "\n",
        "      # Store results for the current weight decay value\n",
        "        results[weight_decay] = fold_results\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58ce1736-5492-4a67-9311-4294831030b0",
      "metadata": {
        "id": "58ce1736-5492-4a67-9311-4294831030b0"
      },
      "source": [
        "# Model improvement"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7ebddb4-ac72-4d8e-9bc7-164b69619894",
      "metadata": {
        "id": "c7ebddb4-ac72-4d8e-9bc7-164b69619894"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4511da9a-0124-4288-82a6-7a36576ad514",
      "metadata": {
        "id": "4511da9a-0124-4288-82a6-7a36576ad514"
      },
      "outputs": [],
      "source": [
        "############################################\n",
        "# benchmark beginning for Cross Validation #\n",
        "############################################\n",
        "time_start_cv = time.perf_counter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "toO_23frOXAC",
      "metadata": {
        "id": "toO_23frOXAC"
      },
      "outputs": [],
      "source": [
        "input_size = 1536     # set from  stella dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40991ebd-b228-4ebe-ae91-f750a75ce5ed",
      "metadata": {
        "collapsed": true,
        "id": "40991ebd-b228-4ebe-ae91-f750a75ce5ed",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "results = train_model(X_train_embeddings, y_train, X_val_embeddings, y_val, input_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LY3T2J4hFv05",
      "metadata": {
        "id": "LY3T2J4hFv05"
      },
      "outputs": [],
      "source": [
        "# Initialize variables to track best metrics\n",
        "best_weight_decay = None\n",
        "best_val_loss = float('inf')\n",
        "best_val_accuracy = 0.0\n",
        "avg_val_losses = []\n",
        "avg_val_accuracies = []\n",
        "\n",
        "for wd, fold_metrics in results.items():\n",
        "    # Calculate the average validation loss and accuracy across folds\n",
        "    avg_val_loss = np.mean([fold['val_losses'][-1] for fold in fold_metrics])  # Average of last validation loss for each fold\n",
        "    avg_val_accuracy = np.mean([fold['val_accuracies'][-1] for fold in fold_metrics])  # Average of last validation accuracy for each fold\n",
        "\n",
        "    avg_val_losses.append(avg_val_loss)\n",
        "    avg_val_accuracies.append(avg_val_accuracy)\n",
        "\n",
        "    # Check if this is the best validation loss\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        best_weight_decay = wd\n",
        "        best_val_accuracy = avg_val_accuracy  # Update the best accuracy when finding a new best loss\n",
        "\n",
        "print(f\"Best Weight Decay: {best_weight_decay:.6f}, Best Validation Loss: {best_val_loss:.6f}, Best Validation Accuracy: {best_val_accuracy:.6f}\")\n",
        "print(\"Average Validation Losses: \", [\"{:.6f}\".format(item) for item in avg_val_losses])\n",
        "print(\"Average Validation Accuracies: \", [\"{:.6f}\".format(item) for item in avg_val_accuracies])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43732b1f-cdf3-450d-a147-0349d3fc86be",
      "metadata": {
        "id": "43732b1f-cdf3-450d-a147-0349d3fc86be"
      },
      "outputs": [],
      "source": [
        "#########################################\n",
        "# Benchmark ending for Cross Validation #\n",
        "#########################################\n",
        "time_end_cv = time.perf_counter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XWZwWED-l27b",
      "metadata": {
        "id": "XWZwWED-l27b"
      },
      "outputs": [],
      "source": [
        "# Visualize the results\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Iterate through each weight decay and its corresponding fold metrics\n",
        "for wd, fold_metrics in results.items():\n",
        "    # Get the lengths of val_losses for each fold\n",
        "    lengths = [len(fold['val_losses']) for fold in fold_metrics]\n",
        "    # Find the minimum length\n",
        "    min_length = min(lengths)\n",
        "    # Truncate val_losses to the minimum length for consistent shapes\n",
        "    truncated_val_losses = [fold['val_losses'][:min_length] for fold in fold_metrics]\n",
        "\n",
        "    # Compute the average validation loss across all folds for each epoch using the truncated lists\n",
        "    avg_val_losses = np.mean(truncated_val_losses, axis=0)  # Average over folds\n",
        "\n",
        "    plt.plot(avg_val_losses, label=f'Weight Decay: {wd}', marker='o')  # Adding marker for better visibility\n",
        "\n",
        "plt.title('Average Validation Loss vs. Epochs for Different Weight Decay Values')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Average Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)  # Add grid for better readability\n",
        "plt.ylim(bottom=0)  # Ensure y-axis starts at 0 for better visibility\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2k0cyEC-1Dhz",
      "metadata": {
        "id": "2k0cyEC-1Dhz"
      },
      "source": [
        "## Retrain the model using the best AdamW decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YT-I6Ovw1DKS",
      "metadata": {
        "id": "YT-I6Ovw1DKS"
      },
      "outputs": [],
      "source": [
        "# Function to train the model\n",
        "def retrain_with_best_decay(X_train, y_train, X_val, y_val, input_size, best_weight_decay):\n",
        "    train_dataset = NewsDataset(X_train, y_train)\n",
        "    val_dataset = NewsDataset(X_val, y_val)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    model = SimpleNN(input_size).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=2e-5, weight_decay=best_weight_decay)\n",
        "\n",
        "    num_epochs = 40\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 2\n",
        "    patience_counter = 0\n",
        "\n",
        "    # Initialize lists to store losses and accuracies\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()  # Accumulate training loss\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += y_batch.size(0)\n",
        "            correct += (predicted == y_batch).sum().item()  # Track correct predictions\n",
        "\n",
        "\n",
        "        avg_train_loss = running_loss / len(train_loader)  # Calculate average training loss\n",
        "        train_accuracy = correct / total  # Calculate training accuracy\n",
        "\n",
        "        train_losses.append(avg_train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                outputs = model(X_batch)\n",
        "                loss = criterion(outputs, y_batch)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += y_batch.size(0)\n",
        "                correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        val_accuracy = correct / total\n",
        "\n",
        "        val_losses.append(avg_val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss:.6f}, Training Accuracy: {train_accuracy:.6f},\\n Validation Loss: {avg_val_loss:.6f}, Validation Accuracy: {val_accuracy:.6f}')\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "    return model, train_losses, val_losses, train_accuracies, val_accuracies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_ok46oQSA0S8",
      "metadata": {
        "id": "_ok46oQSA0S8"
      },
      "outputs": [],
      "source": [
        "##########################################\n",
        "# Benchmark beginning for best modeling  #\n",
        "##########################################\n",
        "time_start_model = time.perf_counter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5uAsMQenA9jc",
      "metadata": {
        "id": "5uAsMQenA9jc"
      },
      "outputs": [],
      "source": [
        "input_size = 1536"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Rx7m_Eut-jnW",
      "metadata": {
        "id": "Rx7m_Eut-jnW"
      },
      "outputs": [],
      "source": [
        "# #Coverting into int\n",
        "# label_mapping = {'real': 0, 'fake': 1}\n",
        "\n",
        "# # Convert y_train and y_val only if they are strings\n",
        "# y_train = [label_mapping.get(label, label) if isinstance(label, str) else label for label in y_train]\n",
        "# y_val = [label_mapping.get(label, label) if isinstance(label, str) else label for label in y_val]\n",
        "\n",
        "# # Ensure all elements are integers before creating tensors\n",
        "# y_train = [int(label) for label in y_train]  # Convert all elements to integers\n",
        "# y_val = [int(label) for label in y_val]  # Convert all elements to integers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87rFZ-7v-nlk",
      "metadata": {
        "id": "87rFZ-7v-nlk"
      },
      "outputs": [],
      "source": [
        "# Train the model with the best weight decay\n",
        "model, train_losses, val_losses, train_accuracies, val_accuracies = retrain_with_best_decay(X_train_embeddings, y_train, X_val_embeddings, y_val, input_size, best_weight_decay)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AUTShmq3nWXj",
      "metadata": {
        "id": "AUTShmq3nWXj"
      },
      "outputs": [],
      "source": [
        "######################################\n",
        "# Benchmark ending for best modeling #\n",
        "######################################\n",
        "time_end_model = time.perf_counter()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97kVEkEgDbsM",
      "metadata": {
        "id": "97kVEkEgDbsM"
      },
      "source": [
        "## Evaluating\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KkeE84sdRJxZ",
      "metadata": {
        "id": "KkeE84sdRJxZ"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate the model on the test set\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    model.eval()\n",
        "    test_dataset = NewsDataset(X_test, y_test)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)  # Create a DataLoader for the test set to ensure processing the test data in batches\n",
        "\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, _ in test_loader:  # We don't need the labels for predictions\n",
        "            X_batch = X_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            y_pred.extend(predicted.cpu().numpy())  # Collect predictions for this batch\n",
        "\n",
        "    return np.array(y_pred)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = evaluate_model(model, X_test_embeddings, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_6GkWHejSDzk",
      "metadata": {
        "id": "_6GkWHejSDzk"
      },
      "outputs": [],
      "source": [
        "# Evaluate performance\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred, target_names=[\"real\", \"fake\"])\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {acc:.6f}\")\n",
        "print(f\"Classification Report:\\n{class_report}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=[\"real\", \"fake\"], yticklabels=[\"real\", \"fake\"])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "plt.savefig('Confusion Matrix.png', transparent = TRUE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kWxAjJVkP_Lg",
      "metadata": {
        "id": "kWxAjJVkP_Lg"
      },
      "outputs": [],
      "source": [
        "# Plot the loss curves\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('Loss curves.png', transparent = TRUE)\n",
        "\n",
        "# Plot the accuracy curves\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Train Accuracy')\n",
        "plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "plt.savefig('Accuracy curves.png', transparent = TRUE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "akMaGh1QXXk4",
      "metadata": {
        "id": "akMaGh1QXXk4"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "print(\"Train Losses:\", train_losses)\n",
        "print(\"Validation Losses:\",val_losses)\n",
        "print(\"Train Accuracies:\", train_accuracies)\n",
        "print(\"Validation Accuracies:\", val_accuracies)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mILYNY7ajaFr",
      "metadata": {
        "id": "mILYNY7ajaFr"
      },
      "outputs": [],
      "source": [
        "print('Train Losses: ', ['{:.6f}'.format(item) for item in train_losses])\n",
        "print('Validation Losses: ', ['{:.6f}'.format(item) for item in val_losses])\n",
        "print('Train Accuracies: ', ['{:.6f}'.format(item) for item in train_accuracies])\n",
        "print('Validation Accuracies: ', ['{:.6f}'.format(item) for item in val_accuracies])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30jsiSAOZdLL",
      "metadata": {
        "id": "30jsiSAOZdLL"
      },
      "outputs": [],
      "source": [
        "# Plot ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "plt.savefig('ROC curve.png', transparent = TRUE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'ROC AUC: {roc_auc:.6f}')"
      ],
      "metadata": {
        "id": "jH49qcm-C8QR"
      },
      "id": "jH49qcm-C8QR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7ad31460-8f94-4de2-be81-aa55e8196ebb",
      "metadata": {
        "id": "7ad31460-8f94-4de2-be81-aa55e8196ebb"
      },
      "source": [
        "## Benchmark results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4efc1ba3-f5f4-4723-bd6e-bbead42ddd5b",
      "metadata": {
        "id": "4efc1ba3-f5f4-4723-bd6e-bbead42ddd5b"
      },
      "outputs": [],
      "source": [
        "#####################################\n",
        "#          Benchmark results        #\n",
        "#####################################\n",
        "# calculating the performances\n",
        "embedding_duration = time_end_embed - time_start_embed\n",
        "cv_duration = time_end_cv - time_start_cv\n",
        "modeling_duration = time_end_model - time_start_model\n",
        "\n",
        "# formating\n",
        "embedding_duration_hms = sec2hms(embedding_duration)\n",
        "cv_duration_hms = sec2hms(cv_duration)\n",
        "modeling_duration_hms = sec2hms(modeling_duration)\n",
        "\n",
        "# printing the embedding, cross validation and modeling performances\n",
        "\n",
        "print(f'Embedding duration : {embedding_duration_hms[0]:.0f}:{embedding_duration_hms[1]:.0f}:{embedding_duration_hms[2]:.3f}')\n",
        "print(f'Cross validation duration : {cv_duration_hms[0]:.0f}:{cv_duration_hms[1]:.0f}:{cv_duration_hms[2]:.3f}')\n",
        "print(f'Best modeling duration : {modeling_duration_hms[0]:.0f}:{modeling_duration_hms[1]:.0f}:{modeling_duration_hms[2]:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fb71ef3-27fb-47bc-8c9b-b1d7dd9aeb17",
      "metadata": {
        "id": "4fb71ef3-27fb-47bc-8c9b-b1d7dd9aeb17"
      },
      "outputs": [],
      "source": [
        "# Save the model state dictionary to a .pth file\n",
        "\"\"\"torch.save(model.state_dict(), 'stella_model.pth')\n",
        "\n",
        "#save to Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save the model state dictionary to Google Drive\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/stella_model.pth')\n",
        "\n",
        "print('Model saved!')\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iRHiE2RbfJPD",
      "metadata": {
        "id": "iRHiE2RbfJPD"
      },
      "source": [
        "the below is not working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HrJtGl4HVVB6",
      "metadata": {
        "id": "HrJtGl4HVVB6"
      },
      "outputs": [],
      "source": [
        "!apt-get install git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rqWoLfZOVbCh",
      "metadata": {
        "id": "rqWoLfZOVbCh"
      },
      "outputs": [],
      "source": [
        "# Set your GitHub username\n",
        "!git config --global user.email \"romeolorena81@gmail.com\"\n",
        "!git config --global user.name \"Anerol18\"\n",
        "\n",
        "# Push changes to GitHub\n",
        "!git add stella_model.pth\n",
        "!git commit -m \"Add stella_model.pth\"\n",
        "!git push https://<Anerol18>:<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>@github.com/Anerol18/Fake_News_Detector_NLP_DeepLearning_Project.git main\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P5wDWGT2VxyD",
      "metadata": {
        "id": "P5wDWGT2VxyD"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Anerol18/Fake_News_Detector_NLP_DeepLearning_Project.git\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hwieK2DhWMhp",
      "metadata": {
        "id": "hwieK2DhWMhp"
      },
      "outputs": [],
      "source": [
        "!mv stella_model.pth Fake_News_Detector_NLP_DeepLearning_Project/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dvSuWHl_WR7S",
      "metadata": {
        "id": "dvSuWHl_WR7S"
      },
      "outputs": [],
      "source": [
        "%cd Fake_News_Detector_NLP_DeepLearning_Project\n",
        "!git add stella_model.pth\n",
        "!git commit -m \"Add stella_model.pth\"\n",
        "!git push origin main  # or the branch you are working on\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iArGSpgrOM8d",
      "metadata": {
        "id": "iArGSpgrOM8d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}